---
permalink: /
title: "Biography"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a tenure-track assistant professor of [Computer Science](https://www.cs.umd.edu/), [UMIACS](https://www.umiacs.umd.edu/), and [AIM](https://aim.umd.edu/) at [University of Maryland, College Park](https://www.umd.edu/). My research interests are in machine learning, optimization, and natural language processing. I am part of the Center for Machine Learning ([CML](https://ml.umd.edu/)) and [CLIP Lab](https://wiki.umiacs.umd.edu/clip/index.php/Main_Page) at UMIACS. I have published [~120 papers](https://scholar.google.com/citations?user=OKvgizMAAAAJ&hl=en) in ML (NeurIPS, ICML, ICLR), NLP (ACL, EMNLP, NAACL), CV (CVPR, ICCV, ECCV), DM (KDD, ICDM), AI (AAAI, IJCAI) conferences, and journals as Machine Learning (Springer), IEEE TPAMI/TIP/TNNLS/TKDE, etc. 
<!-- I am the recipient of the [Best Student Paper Award at ICDM 2013](https://tianyizhou.files.wordpress.com/2010/08/dca-paper.pdf) and the [2020 IEEE TCSC Most Influential Paper Award](http://www.icml-2011.org/papers/41_icmlpaper.pdf). -->

Our recent works study (1) How, why, and when to transfer human learning (e.g., curriculum, retention, sub-tasking, curiosity, exemplar selection, collaboration, etc.) to improve machine learning and generalization in the wild (e.g., with unlabeled, biased, noisy, redundant, or distributed data, in unseen tasks/environments); (2) Controllable Generative AI in both training and inference/adaptation; (3) Synthetic data, self-evolving AI, and auto-benchmarking; and (4) Human-AI teaming and hybrid agent with personalization. 
<!-- Our works are built upon empirical/theoretical analysis to the learning dynamics of neural networks and tools from discrete and continuous optimization.  -->
We are developing these methods with LLMs, multi-modality foundation models, and RL. Our goal is to develop efficient, versatile, trustworthy, and environmentally-friendly hybrid-intelligence based on coevolution between human and machine. The code/data/models can be found at [Tianyi Lab's GitHub](https://github.com/tianyi-lab) and [HF](https://huggingface.co/umd-zhou-lab). 

I was a visiting research scientist at Google between 2021-2022, hosted by [Boqing Gong](http://boqinggong.info/) and [Ming-Hsuan Yang](https://faculty.ucmerced.edu/mhyang/). Before that, I received my Ph.D. ([thesis](https://digital.lib.washington.edu/researchworks/items/6512d9f6-be50-431e-88dd-8359c737a204/full)) from [Computer Science](https://www.cs.washington.edu/) of [University of Washington](https://www.washington.edu/), where I was a member of [MELODI lab](https://melodi.ece.uw.edu/) led by [Prof. Jeff A. Bilmes](https://people.ece.uw.edu/bilmes/p/pgs/index.html). I have been working with [Prof. Dacheng Tao](https://dr.ntu.edu.sg/cris/rp/rp02343) as a research assistant at [University of Technology, Sydney (UTS)](https://www.uts.edu.au/) and [Nanyang Technological University](https://www.ntu.edu.sg/Pages/home.aspx). I was a research intern at [Yahoo! Labs](https://research.yahoo.com/), mentored by [Dr. Hua Ouyang](https://www.linkedin.com/in/hua-ouyang-5869b851) (Apple) and [Prof. Yi Chang](http://www.yichang-cs.com/) (Jilin University), and a research intern at [Microsoft Research](https://www.microsoft.com/en-us/research/), mentored by [Dr. Lin Xiao](https://linxiaolx.github.io/) (Meta AI). 
<!-- I also work closely with several members and students of [Australian AI Institute](https://www.uts.edu.au/research-and-teaching/our-research/australian-artificial-intelligence-institute). -->
<!--  and [Tencent AI Lab](https  ://ai.tencent.com/ailab/en/index) My collaborators also include members from [Chengqi Zhang](https://profiles.uts.edu.au/Chengqi.Zhang) and [Guodong Long](https://profiles.uts.edu.au/Guodong.Long)'s groups in [Australian AI Institute](https://www.uts.edu.au/research-and-teaching/our-research/australian-artificial-intelligence-institute) at University of Technology, Sydney, and [Meng Fang](https://mengf1.github.io/) at Tencent AI Lab. -->

News
------
* 2025/02: Check the first "Aha moment" of multimodal reasoning by RL [here](https://github.com/turningpoint-ai/VisualThinker-R1-Zero) acheived by VisualThinker-R1-Zero from our [Turningpoint-AI](https://www.turningpoint-ai.com/people)
* 2025/01: 7 ICLR + 3 NAACL accepted, featuring our latest works on [synthetic data for post-training](https://github.com/tianyi-lab/RuleR), [MoE](https://github.com/tianyi-lab/MoE-Embedding) <span style="color:red">*(ICLR Oral)*</span>, [many-objective optimization](https://arxiv.org/pdf/2403.04099), [in-context transferality](https://github.com/tianyi-lab/bento), [multi-modality imbalance](https://arxiv.org/pdf/2410.12219) & [alignment](https://arxiv.org/pdf/2405.15973), [oversensitiveness](https://github.com/xirui-li/MOSSBench) & [controllability of GenAI](https://arxiv.org/pdf/2406.01970). 
* 2024/12: I am going to serve as an Area Chair for [ARR](https://aclrollingreview.org/) Dec 2024 & Feb 2025 ([ACL 2025](https://2025.aclweb.org/)). 
* 2024/11: I am going to serve as an Area Chair (SPC) for [IJCAI 2025](https://2025.ijcai.org/). 
* 2024/09: Five papers (3 main + 2 findings) have been accepted by [EMNLP 2024](https://2024.emnlp.org/). 
* 2024/09: I am going to serve as an Area Chair of [ICLR 2025](https://iclr.cc/). 
* 2024/07: We initialize [TurningPoint AI](https://www.turningpoint-ai.com/), a research team from multiple universities and industry ([UMD+UCLA+PSU+Google](https://www.turningpoint-ai.com/people)) investigating Muiltimodal Agents, with the goals of building Trustworthy Embodied AI, Self-Evolving Machines, Compositional Agents, and Controllable AIGC. We already released [8 projects](https://www.turningpoint-ai.com/publications) with several ICML and ECCV publications and new datasets. 
* 2024/07: 2 papers of diffusion models ([analysis of negative prompts](https://arxiv.org/pdf/2406.02965), [extracting discriminative features from generative models](https://arxiv.org/pdf/2311.17921)) have been accepted by ECCV 2024.
* 2024/05: 4 ICLR + 4 ICML + 6 ACL + 2 NAACL + 2 CVPR have been accepted, featuring our works on controllable AIGC, personalized AI, data-efficient training of LLMs, RLHF, prompt optimization, multi-modal hallucinations, multi-modal and embodied agent, and curriculum reinforcement learning. 
* 2024/02: We release [a survey on knowledge distillation of LLMs](https://arxiv.org/pdf/2402.13116) with [GitHub repo](https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs).
* 2023/11: I will give a talk "[Towards Controllable and Personalized AI Models](https://www.cs.umd.edu/event/2023/10/towards-controllable-and-personalized-ai-models)" at UMD CS department seminar on 11/03. 
* 2023/10: We release [HallusionBench](https://github.com/tianyi-lab/HallusionBench) focusing on the Language Hallucination and Visual Illusion of GPT-4V(ision), Llava-1.5, and other multi-modality models. Analyses and insights can be found in the [preprint](https://arxiv.org/abs/2310.14566). 
* 2023/10: Data recycling and filtering improves instruction-tuning of LLMs, leading to recycled LLMs outperforming other larger LLMs trained on new data and RLHF. We release [Reflection-Tuning preprint](https://arxiv.org/abs/2310.11716), [codebase](https://github.com/tianyi-lab/Reflection_Tuning), and the [model](https://huggingface.co/umd-zhou-lab/recycled-wizardlm-7b-v2.0). 
* 2023/10: Two papers ([How Many Demonstrations Do You Need for In-context Learning](https://arxiv.org/pdf/2303.08119.pdf), [Merging Mixture-of-Experts into One](https://arxiv.org/pdf/2310.09832.pdf)) have been accepted by [EMNLP 2023](https://2023.emnlp.org/). 
* 2023/09: Two papers ([multi-modality model distillation for task adaptation](https://arxiv.org/pdf/2310.04550.pdf), [clustered additive modeling for structured federated learning](https://openreview.net/pdf?id=2XT3UpOv48)) have been accepted by [NeurIPS 2023](https://neurips.cc/). 


Research Topics
------
* Machine Learning (2008-present)
  1. Learning over time: Curriculum Learning, Continual Learning ([DisCL](https://github.com/tianyi-lab/DisCL), [DIH](https://github.com/tianyizhou/DIHCL), [DoCL](https://github.com/tianyizhou/DoCL), [MECE](http://proceedings.mlr.press/v119/zhou20d/zhou20d.pdf), [Time-Consistency](http://proceedings.mlr.press/v119/zhou20d/zhou20d.pdf), [RAR](https://github.com/lillykumari8/RAR-CL), [FPF](https://proceedings.mlr.press/v202/zhao23n/zhao23n.pdf), [CoTASP](https://github.com/stevenyangyj/CoTASP))
  1. Learning via interactions: Reinforcement Learning, Online Learning ([CHER](https://github.com/mengf1/CHER), [Unsupervised RL](https://openreview.net/pdf?id=zSxpnKh1yS), [CO-PILOT](https://github.com/Shuang-AO/CO-PILOT), [P3](https://github.com/stevenyangyj/P3))
  1. Learning across tasks/domains: Multi-task Learning, Meta-Learning, Domain Adaptation/Generalization ([GPN](https://github.com/liulu112601/Gated-Propagation-Net), [PPN](https://github.com/liulu112601/Prototype-Propagation-Net), [MTC](https://dl.acm.org/doi/abs/10.1145/2623330.2623697?download=true))
  1. Learning multiple models: Mixture-of-Experts (MoE), Collaborative/Cooperative Learning, Federated/Decentralized Learning ([MoEE](https://github.com/tianyi-lab/MoE-Embedding), [DivE2](https://papers.nips.cc/paper_files/paper/2018/file/3070e6addcd702cb58de5d7897bfdae1-Paper.pdf), [L2C](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.pdf), [SCooL](https://github.com/ShuangtongLi/SCooL), [DivFL](https://github.com/melodi-lab/divfl), [FedProto](https://github.com/yuetan031/FedProto), [FedRAP](https://github.com/mtics/FedRAP), [CAM](https://openreview.net/pdf?id=2XT3UpOv48))
  1. Learning under noises: Noisy-Label Learning, Adversarial Learning ([RoCL](https://openreview.net/pdf?id=lmTWnm3coJJ), [CD-VAE](https://github.com/kai-wen-yang/CD-VAE))
  1. Learning representations: Self-Supervised Learning, Dimension Reduction ([MEN](https://arxiv.org/pdf/1007.3564), [LPA3](https://github.com/kai-wen-yang/LPA3), [IDAA](https://github.com/kai-wen-yang/IDAA))
  1. Sparse Learning: Compressed Sensing, Matrix Factorization, Spectral Method ([GoDec](https://icml.cc/Conferences/2011/papers/41_icmlpaper.pdf), [DCA](https://arxiv.org/pdf/1406.5752.pdf), [k-bit HCS](https://ieeexplore.ieee.org/document/6620312))
  1. Optimization: Continuous, Combinatorial, Multi-Objective, Zeroth-order ([MosT](https://arxiv.org/pdf/2403.04099), [Minimax CL](https://openreview.net/pdf?id=BywyFQlAW), [Submodular Partition](https://proceedings.neurips.cc/paper/2021/file/161882dd2d19c716819081aee2c08b98-Paper.pdf), [TSAM](https://arxiv.org/pdf/2410.22656))
  1. Controllable Generative AI

* Natural Language Processing (2016-present)
  1. Attention mechanisms: [DiSAN](https://github.com/taoshen58/DiSAN), [BiBloSA](https://github.com/taoshen58/BiBloSA)
  1. Data Engineering (selection, exploration, synthesis) for Large language models (LLMs) training: [Reflection-Tuning](https://github.com/tianyi-lab/Reflection_Tuning), [SuperFiltering](https://github.com/tianyi-lab/Superfiltering), [Alpagasus](https://lichang-chen.github.io/AlpaGasus/), [Cherry LLM](https://github.com/MingLiiii/Cherry_LLM), [Mosaic-IT](https://github.com/tianyi-lab/Mosaic-IT), [RuleR](https://github.com/tianyi-lab/RuleR)
  1. LLM Agents, NeuroSymbolic World Models: [WALL-E](https://github.com/elated-sawyer/WALL-E), [DynaSaur](https://github.com/adobe-research/dynasaur)
  1. Personalization and Human-AI Alignment: [DEBATunE](https://github.com/tianyi-lab/DEBATunE), [MCTune](https://github.com/tianyi-lab/mctune), [CAIMIRA](https://youtu.be/joeNRMM5abI)
  1. Prompt Optimization: [InstructZero](https://github.com/Lichang-Chen/InstructZero), [MoP](https://github.com/ruocwang/mixture-of-prompts)
  1. In-Context Learning: [BenTo](https://github.com/tianyi-lab/BenTo), [Div-S3](https://github.com/lillykumari8/ICL-Div-S3)
  1. Embedding: [MoEE](https://github.com/tianyi-lab/MoE-Embedding), [MetaEOL](https://github.com/Yibin-Lei/MetaEOL)
  1. Efficient Inference: [SpecHub](https://github.com/MasterGodzilla/Speculative_decoding_OT), [BumbleBee](https://openreview.net/pdf?id=8w0RApM5yG)
  1. Adversarial attack and defense（Jailbreak, Unlearning, etc.): [DrAttack](https://github.com/xirui-li/DrAttack)

* Multi-modality Models (2021-present)
  1. Vision-Language Models and Dense Alignment across modalities: [Florence-VL](https://github.com/JiuhaiChen/Florence-VL)
  1. VLM + RL, Multi-modality Embodied-AI: [EMMA](https://github.com/stevenyangyj/Emma-Alfworld), [CoTASP](https://github.com/stevenyangyj/CoTASP)
  1. Multi-modal Generative Agents: [MuLan](https://github.com/measure-infinity/mulan-code)
  1. Hallucinations, Illusions, Oversensitivity: [HallusionBench](https://github.com/tianyi-lab/HallusionBench), [AutoHallusion](https://github.com/wuxiyang1996/AutoHallusion), [MOSSBench](https://github.com/xirui-li/MOSSBench)

<br />
<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=yS55EhS2ol9nZNevQxAHb2-_nUUI3Opt9QjGnAYIFrg" size="1"></script>
<br />

<!-- 
* 2023/07: Two papers ([model-adaptive data augmentation curriculum](https://arxiv.org/pdf/2309.04747.pdf), [subclass balancing for long-tail recognition](https://arxiv.org/pdf/2306.15925.pdf))  have been accepted by [ICCV 2023](https://iccv2023.thecvf.com/). 
* 2023/06: How to efficiently optimize the textual instructions applied to API black-box LLMs (e.g., ChatGPT) for solving downstream tasks? Please check our recent work [InstructZero](https://lichang-chen.github.io/InstructZero/), [paper](http://arxiv.org/abs/2306.03082) and [code](https://github.com/Lichang-Chen/InstructZero) have been released.
* 2023/06: Invited talk at Purdue Statistics on "Structured Decentralized Learning".
* 2023/06: Two papers ([Meta-Vote Pruning](https://arxiv.org/pdf/2301.11560.pdf) and [Eigensubspace of Temporal-Difference Dynamics](https://arxiv.org/pdf/2306.16750.pdf)) have been accepted by [ECML/PKDD 2023](https://2023.ecmlpkdd.org/). 
* 2023/05: I will teach CMSC-421 on "Introduction to Artificial Intelligence" in Fall 2023.
* 2023/04: Three papers ([training dynamics of continual learning](ttps://arxiv.org/pdf/2304.04158.pdf), [continual RL via sparse prompting](https://arxiv.org/pdf/2305.18444.pdf), [structured cooperative learning](https://github.com/ShuangtongLi/SCooL/blob/main/paper/SCooL_ICML2023.pdf)) have been accepted by [ICML 2023](https://icml.cc/). See you at Hawaii in July!
* 2023/04: One paper about personalization in federated recommendation system has been accepted by [IJCAI 2023](https://ijcai-23.org/). 
* 2022/12: I will teach CMSC-828A on "Fantastic Machine Learning Paradigms and Where to use Them" in Spring 2023.
* 2022/12: I will serve as an SPC (meta-reviewer) for [IJCAI 2023](https://ijcai-23.org/).
* 2022/11: One [XAI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence) paper on extracting local reasoning chains for subtasks from neural networks such as ResNet and ViT has been accepted by [TMLR](https://www.jmlr.org/tmlr/).
* 2022/10: One paper ([adversarial attacks to Question-Answer models](https://arxiv.org/pdf/2210.15221.pdf)) has been accepted by [EMNLP 2022](https://2022.emnlp.org/).
* 2022/09: Three papers ([adversarial augmentation for continual learning](https://openreview.net/pdf?id=XEoih0EwCwL), [adversarial augmentation for representation learning](https://arxiv.org/pdf/2211.00824.pdf), [federated learning from pre-trained models](https://arxiv.org/pdf/2209.10083.pdf)) have been accepted by [NeurIPS 2022](https://neurips.cc/).
* 2021/12: One paper of [Federated Prototype Learning](https://arxiv.org/pdf/2105.00243.pdf) has been accepted to [AAAI 2022](https://aaai.org/Conferences/AAAI-22/).
* 2021/11: I will serve as an SPC for [SIGKDD 2022](https://kdd.org/kdd2022/). 
* 2021/09: Three papers (1 spotlight for [Submodular Partitioning](https://papers.nips.cc/paper/2021/file/161882dd2d19c716819081aee2c08b98-Paper.pdf), [Curriculum RL and Planning](https://papers.nips.cc/paper/2021/file/56577889b3c1cd083b6d7b32d32f99d5-Paper.pdf), [Class-Disentanglement](https://proceedings.neurips.cc/paper/2021/file/8606f35ec6c77858dfb80a385d0d1151-Paper.pdf)) have been accepted to [NeurIPS 2021](https://nips.cc/). Congratulations to Shuang Ao and Kaiwen Yang for their first paper!
* 2021/09: [One paper of sentiment bias](https://arxiv.org/pdf/2109.02403.pdf) has been accepted to [EMNLP 2021](https://2021.emnlp.org/) (findings). 
* 2021/08: I will serve as an SPC for [AAAI 2022](https://aaai.org/Conferences/AAAI-22/).
* 2021/02: I am selected as an expert reviewer for [ICML 2021](https://icml.cc/Conferences/2021).
* 2021/01: [One paper of curriculum learning and training dynamics](https://drive.google.com/file/d/13_uEga3FVBZGSZTHbBEcMOouSYVcJ9VI/view?usp=sharing) has been accepted to [AISTATS 2021](https://aistats.org/aistats2021/).
* 2021/01: Three papers ([RoCL for curriculum noisy-label learning](https://openreview.net/pdf?id=lmTWnm3coJJ), [AutoLRS for auto-learning rate schedule](https://openreview.net/pdf?id=SlrqM9_lyju), [IPN for prototype zero-shot learning](https://openreview.net/pdf?id=-mWcQVLPSPy)) have been accepted to [ICLR 2021](https://iclr.cc/).
* 2021/01: [One paper of knowledge graph completion](https://arxiv.org/pdf/2004.14781.pdf) has been accepted to [WWW 2021](https://www2021.thewebconf.org/).
* 2020/10: Selected among the top 10% of high-scoring reviewers for [NeurIPS 2020](https://nips.cc/).
* 2020/09: [One paper of curriculum learning and training dynamics](https://proceedings.neurips.cc/paper/2020/file/62000dee5a05a6a71de3a6127a68778a-Paper.pdf) has been accepted to [NeurIPS 2020](https://nips.cc/).
* 2020/06: [One paper of curriculum semi/self-supervised learning](http://proceedings.mlr.press/v119/zhou20d/zhou20d.pdf) has been accepted to [ICML 2020](https://icml.cc/Conferences/2020). 
* 2022/06: I will serve as an Area Chair for Winter Conference on Applications of Computer Vision ([WACV](https://wacv2023.thecvf.com/home)) 2023.
* 2022/05: Two papers about [environment-and-task-curriculum for RL](https://proceedings.mlr.press/v162/ao22a/ao22a.pdf) and [adversarial augmentation for self-supervised learning](https://proceedings.mlr.press/v162/yang22s/yang22s.pdf) have been accpeted by [ICML 2022](https://icml.cc/).
* 2022/04: One paper about [personalized federated learning](https://arxiv.org/pdf/2203.00829.pdf) has been accpeted by [IJCAI 2022](https://ijcai-22.org/) as a long presentation.
* 2022/04: One paper of [phrase-level textual adversarial attack with label preservation](https://arxiv.org/pdf/2205.10710.pdf) has been accpeted by [NAACL 2022](https://2022.naacl.org/) Findings.  
* 2022/03: One paper ([Learning to Collaborate in Decentralized Learning of Personalized Models](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.pdf)) has been accepted by [CVPR 2022](https://cvpr2022.thecvf.com/).
* 2022/02: One paper ([Token Dropping for Efficient BERT Pretraining](https://arxiv.org/pdf/2203.13240.pdf)) has been accepted by [ACL 2022](https://www.2022.aclweb.org/).
* 2022/01: Three papers ([Pareto Policy Pool for Model-based Offline RL](https://openreview.net/pdf?id=OqcZu8JIIzS), [Diverse Client Selection for Federated Learning](https://openreview.net/pdf?id=nwKXyFvaUm), [Omni-scale CNNs for Time Series](https://openreview.net/pdf?id=PDYs7Z2XFGv)) have been accepted by [ICLR 2022](https://iclr.cc/Conferences/2022).-->

<!--   1. Curriculum Learning (for 2-6 below, using tools in 7-8)
  1. [Self-supervised/Semi-supervised Learning](http://proceedings.mlr.press/v119/zhou20d/zhou20d.pdf)
  1. [Reinforcement Learning](https://papers.nips.cc/paper/2019/file/83715fd4755b33f9c3958e1a9ee221e1-Paper.pdf) 
  1. [Collaborative Learning on graphs/networks](https://github.com/ShuangtongLi/SCooL/blob/main/paper/SCooL_ICML2023.pdf), [Ensemble and Mixture-of-Experts](https://papers.nips.cc/paper/7831-diverse-ensemble-evolution-curriculum-data-model-marriage.pdf)
  1. [Robust Learning on Noisy Data](https://openreview.net/pdf?id=lmTWnm3coJJ)
  1. [Meta-Learning](https://papers.nips.cc/paper/2019/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf), [Few-shot](https://www.ijcai.org/Proceedings/2019/0418.pdf)/[Zero-shot Learning](https://openreview.net/pdf?id=-mWcQVLPSPy)
  1. [Training Dynamics](https://proceedings.neurips.cc/paper/2020/file/62000dee5a05a6a71de3a6127a68778a-Paper.pdf) and [Geometry](http://proceedings.mlr.press/v97/wang19q/wang19q.pdf) of Neural Networks
  1. [Continuous-discrete Optimization](https://openreview.net/pdf?id=BywyFQlAW), [Submodular Optimization](http://proceedings.mlr.press/v54/zhou17a/zhou17a.pdf)
  1. Spectral Method for [Matrix Factorization](https://tianyizhou.files.wordpress.com/2010/08/dca-paper.pdf) and [Graphical Models](https://arxiv.org/pdf/1406.5752.pdf)
  1. Matrix/Tensor Factorization: [Low-rank Approximation](https://tianyizhou.files.wordpress.com/2010/08/brpisit.pdf), [Completion](http://proceedings.mlr.press/v31/zhou13b.pdf), [Robust PCA](http://www.icml-2011.org/papers/41_icmlpaper.pdf), [NMF](https://tianyizhou.files.wordpress.com/2010/08/dca-paper.pdf)
  1. Compressed Sensing ([1-bit](https://tianyizhou.files.wordpress.com/2010/08/hcsisit5pages.pdf) and [k-bit](https://tianyizhou.files.wordpress.com/2010/08/kbithcs.pdf) measurements), [Sparse Learning](https://tianyizhou.files.wordpress.com/2010/08/ds.pdf)
  1. Dimension Reduction, [Manifold Learning](http://arxiv.org/PS_cache/arxiv/pdf/1007/1007.3564v3.pdf)
  1. [Multi-label Learning](https://tianyizhou.files.wordpress.com/2011/12/cl.pdf) -->
  
<!--   1. [Natural Language Inference](https://arxiv.org/pdf/1709.04696.pdf)
  1. [Semantic Role Labeling](https://www.aclweb.org/anthology/N19-1127.pdf)
  1. [Link Prediction in Knowledge Graphs](https://arxiv.org/pdf/2004.14781.pdf)
  1. [Text Classification](https://openreview.net/pdf?id=H1cWzoxA-)
  1. [Summarization](https://arxiv.org/pdf/2002.07338.pdf) -->

<!-- Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
 -->